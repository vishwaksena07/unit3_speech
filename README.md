**Project Title :**
Building a Speech-to-Text System with
Integrated Language Modeling for Improved
Accuracy in Transcription Services
# ivr-speech-to-text
This project implements a speech-to-text transcription system optimized for Interactive Voice Response (IVR) applications. It leverages Wav2Vec2 from HuggingFace Transformers for transcription and simulates real-world call center environments by injecting background noise into IVR prompts. The system evaluates performance using Word Error Rate (WER) and demonstrates robustness against audio interference common in customer service automation.
**ðŸ”‘ Key Features**

âœ… Noise-Robust Transcription: Simulates noisy call center environments using real-world background audio.

âœ… Preprocessing Pipeline: Adds configurable background noise at various SNR levels to clean IVR prompts.

âœ… Speech-to-Text Inference: Uses pretrained Wav2Vec2 models from HuggingFace for accurate transcription.

âœ… Evaluation with WER: Measures transcription quality using Word Error Rate (WER) via the jiwer library.

âœ… Domain-Specific Focus: Designed for IVR use cases like customer service automation and call routing.

âœ… Visualization Support: Includes waveform and spectrogram plots to explore audio characteristics.

âœ… Modular Code: Separated scripts for preprocessing, inference, evaluation, and EDA.

**ðŸ›  Tools & Technologies Used**

Python 3.x

Hugging Face Transformers (Wav2Vec2)

PyTorch (backend for model inference)

librosa (audio processing and visualization)

soundfile (audio file I/O)

jiwer (Word Error Rate calculation)

matplotlib (EDA visualizations)

Jupyter Notebooks or Python scripts (for development and demonstration)
